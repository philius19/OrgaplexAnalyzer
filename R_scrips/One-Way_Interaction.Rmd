---
title: "Orgaplex One-Way Interaction"
output: html_notebook
---

```{r}
library(plyr)  
library(openxlsx)  # Better than xlsx package - install if needed
# install.packages("openxlsx")
```

The first part of the script explains everything for manual analysis. The second part will explain the automated analysis script. ´ The introductory part should allow you to fix further issues with the script and apply those analysis to other formatting tasks (for the case I finished my thesis and you cannot ask me for help). 

Start with setting the Working-Dir for the Analysis. When you run R code in a notebook chunk (RMarkdown/Quarto), each chunk operates in a temporary execution environment (`setwd()`does not work here). 

For the next experiments please start to name the folders with "_" as spaceholder. 
Example: "/Cells without N and without LD" should be named "Cells_without_N_and_without_LD"

This will make your life much easier as many languages can`t handle plain spacings in the folder names. 

```{r}
base_path <- "/Users/philippkaintoch/Documents/Projects/07_R-Scripts_Chahat/Raw_data_for_Orgaplex_Test/Cells_without_N_and_without_LD/Control"

```

Now we start with managing the data setup the following commands are for diagnostic purposes. Here you can see a list of every dataset which is in your folder.  

```{r}
list.files(base_path)
# Output: character vector
# Example: ["file1.txt", "file2.csv", "script.R"]
```

Now we grep the fist dataset in the parent folder and search for the required pattern for manual data accessment.You could modify the so called "wildcard search" by editing the `pattern` argument. You can delete the argument `full.names` if you just want the file names. 

```{r}

subdir_path <- file.path(base_path, "control_1_ER_Statistics")

files <- list.files(subdir_path, 
                    pattern = "Shortest_Distance_to_Surfaces_Surfaces",
                    full.names = TRUE)

print(files)

```
Now we managed the data access. Now we start the first file of the dataset containing our flag into a dataframe. We can access every single frame by indexing.  

```{r}

df <- read.csv(files[1],        # Corresponds to the first path in our file list 
               sep = ",",       # The data is seperated by ","
               skip = 4,        # We skip the first 4 rows 
               header = FALSE   # We dont need a header
               )

print(df)

```
We can now take this basic code components and pack them into a loop. Which just means we take our list `files`, which contains the full directory of all files with our flagg and pack every document into a dataframe which is named according to the file name. 

```{r}

# Create empty list to store dataframes
data_list <- list()

# Loop through all files
for (file_path in files) {
  # Get just the filename for naming
  filename <- basename(file_path)
  
  
  # Remove .csv extension for cleaner name
  df_name <- gsub("\\.csv$", "", filename)
  
  # Read CSV
  df <- read.csv(file_path, 
                 sep = ",", 
                 skip = 4, 
                 header = FALSE)
  
  # Store in list
  data_list[[df_name]] <- df
  
  print(paste("Loaded:", df_name))
}
```
We have now defined a variable `data_list`.
This list contains all of our dataframes (imagine like an excel-sheet with many pages). You can acces those with the following command: 

```{r}
data_list[["control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=LD"]]
```
The data setup is now the following: 

data_list <- list(
    "control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=LD" = df1,
    "control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=Ly" = df2,
    "control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=M"" = df3
    "control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=P" = df4
)

df 1-4 corresponds to the data which is stored in the csv file with the name respectively. Now you have loadad all of the data into your RAM (stored in R) and even if you would delete the file you would keep the data for the rest of the session here (but please don't try that). 

Now the rest of our operations are straigtforward. We take the first column, count the values and calculate the mean. Then we can store the data in the format we wish for. 

PS: For: 

sample <- gsub("^([^_]+_[^_]+)_.*", "\\1", df_name)

the weird stuff is called RegEx (Regular expressions), you can search it up when necessary. Its just for naming the columns correctly. 


```{r}

# Define all organelles
organelles <- c("ER", "M", "P", "Ly", "LD")

# Your existing data_list
# Example name: "control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=LD"

# Create results storage
results <- data.frame(
  Sample = character(),
  Interaction = character(),
  Source = character(),
  Target = character(),
  Mean = numeric(),
  Count = integer(),
  stringsAsFactors = FALSE
)

# Loop through all dataframes
for (df_name in names(data_list)) {
  
  # Get the dataframe
  df <- data_list[[df_name]]
  
  # ===== Extract Sample Name (by splitting) =====
  # Split by underscore
  parts <- strsplit(df_name, "_")[[1]]
  # Combine first two parts: "control" + "1" = "control_1"
  sample <- paste(parts[1], parts[2], sep = "_")
  
  # ===== Find Source Organelle =====
  source <- NA
  for (org in organelles) {
    # Check if organelle appears before "_Shortest"
    pattern <- paste0("_", org, "_Shortest")
    if (grepl(pattern, df_name)) {
      source <- org
      break  # Stop once we find it
    }
  }
  
  # ===== Find Target Organelle =====
  target <- NA
  for (org in organelles) {
    # Check if organelle appears after "Surfaces="
    pattern <- paste0("Surfaces=", org)
    if (grepl(pattern, df_name)) {
      target <- org
      break
    }
  }
  
  # Create interaction name
  interaction <- paste0(source, "_to_", target)
  
  # Calculate metrics
  mean_value <- mean(df[, 1], na.rm = TRUE)
  count_value <- sum(!is.na(df[, 1]))
  
  # Add to results
  results <- rbind(results, data.frame(
    Sample = sample,
    Interaction = interaction,
    Source = source,
    Target = target,
    Mean = mean_value,
    Count = count_value,
    stringsAsFactors = FALSE
  ))
  
  print(paste("✓", sample, "-", interaction, "| Mean:", round(mean_value, 3), "| Count:", count_value))
}

# View results
print(results)

# Export
output_path <- file.path(base_path, "Organelle_Interactions_Summary.xlsx")
write.xlsx(results, output_path, rowNames = FALSE)
```

The for-loop here looks a bit more complex. Most the inner loops (loops in the loop) are used for correct naming. We define basically the organelles (this c() containing organelles) as "search" pattern. Those organelles are then cross searched in the naming of our original dataframe and renamed in shorter notation. I can remove that if its easier for you. 

The file is exported as excel. Look at the file and then at the code, maybe the algorithm here is much easier to understand. You have with those few codelines basically everything you need to build your own pipeline. We can go trough some processes here if you want to learn a bit more background. 

###########################################

# How to use the automated R script? 

The R script automatically analyzes organelle interactions from Imaris-generated data. It processes shortest distance measurements between different organelles and exports results as Excel files (one per cell).

Important: The automated script uses RefEx (Regular Expressions) for pattern matching. I used that because its the most robust and flexible way to group specific characters together. If you want to change anything there you can just lookup RegEx (its like a special language to define patterns). Above I don't used that because I wanted to demonstrate a simpler way how you could do that. 

## What the script does 

1. **Automatic LD Detection**
   - The script automatically detects whether your dataset contains Lipid Droplets (LD) based on folder structure
   - No manual configuration needed.

2. **Comprehensive Organelle Recognition**
   - Recognizes all organelles: ER, LD, Ly, M, P. G
   - Handles multi-character organelle abbreviations (ER, LD)

3. **File Organization**
   - Creates a dedicated `Organelle_Interaction_Results` folder for all outputs
   - One Excel file per cell with clear naming: `{cell_id}_Organelle_Interactions.xlsx`
   
4. **Detailed Progress Output**
   - Shows which organelles are detected
   - Displays each interaction as it's processed
   - Reports warnings for missing data


## How to use 

**Step 1: Set Your Parent Directory **
Open `One_Way_Improved.R` and edit line 33:

```r
parent_dir <- "/path/to/your/parent/directory"
```

**Examples:**
For datasets **with LD** (direct structure):
```r
parent_dir <- "/Users/yourname/Data/Cells_with_LD"
```

For datasets **without LD** (nested structure with Control/Treatment folders):
```r
parent_dir <- "/Users/yourname/Data/Cells_without_LD"
```

**Step 2: Run the Script**
In R or RStudio:
```r
source("One_Way_Improved.R")
```

Or from command line:
```bash
Rscript One_Way_Improved.R
```
or press tge green "run" button in R Studio 

**Step 3: Check the Output**
The script creates an `Organelle_Interaction_Results` folder containing:
- One Excel file per cell
- Each file contains all organelle interactions for that cell

**Output Format**

Each Excel file contains 5 columns:

| Column | Description | Example |
|--------|-------------|---------|
| **Source** | Organelle from which distance is measured | ER |
| **Target** | Organelle to which distance is measured | LD |
| **Interaction** | Combined interaction name | ER_to_LD |
| **Mean_Distance** | Average distance in micrometers (µm) | 5.87 |
| **Count** | Number of distance measurements | 2260 |

## Data Structure Requirements

### Structure 1: With LD (Direct)
```
parent_dir/
  ├── control_1_ER_Statistics/
  ├── control_1_LD_Statistics/
  ├── control_1_Ly_Statistics/
  ├── control_1_M_Statistics/
  ├── control_1_P_Statistics/
  ├── control_3_ER_Statistics/
  └── ...
```

### Structure 2: Without LD (Nested)
```
parent_dir/
  ├── Control/
  │   ├── control_1_ER_Statistics/
  │   ├── control_1_Ly_Statistics/
  │   ├── control_1_M_Statistics/
  │   └── ...
  ├── Treatment/
  │   ├── treated_1_ER_Statistics/
  │   └── ...
  └── ...
```

## Required Files

Within each `*_Statistics` folder, the script looks for files matching:
```
*_Shortest_Distance_to_Surfaces_Surfaces*.csv
```

Example filename:
```
control_1_ER_Shortest_Distance_to_Surfaces_Surfaces=LD.csv
```

## Troubleshooting

### Error: "No valid cell folders found"
- Check that `parent_dir` points to the correct folder
- Verify folder names end with `_Statistics`

### Error: "No folders ending with '_Statistics' found"
- If using nested structure, script will automatically look in subdirectories
- Check that subdirectories (like "Control") exist

### Warning: "Could not identify target organelle"
- This happens if a file references an organelle not in the main list
- The script will skip these files and continue

### No distance files found for an organelle
- This is normal - not every organelle has distance measurements in every cell
- The N and N2 organelles often don't have distance files

## Requirements

- R (version 3.6 or higher)
- `openxlsx` package

To install the package:
```r
install.packages("openxlsx")
```
## Example Workflow

1. Segment your microscopy data in Imaris
2. Export Statistics folders (this is automatic in Imaris)
3. Organize folders according to Structure 1 or 2
4. Set `parent_dir` in the script
5. Run the script
6. Open the `Organelle_Interaction_Results` folder
7. Analyze your Excel files in Excel, GraphPad Prism, or R

## Version History

- **v_b_0.5** (2025-10-09): Improved version with automatic LD detection, better regex, comprehensive annotations





